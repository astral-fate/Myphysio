{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43235291",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data import BodyPart \n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19f3556b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflowjs in c:\\users\\ajarir\\appdata\\roaming\\python\\python310\\site-packages (3.19.0)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in c:\\users\\ajarir\\appdata\\roaming\\python\\python310\\site-packages (from tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: protobuf==3.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflowjs) (3.20.0)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: packaging~=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflowjs) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (16.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (4.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.54.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (65.6.3)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ajarir\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install --user tensorflowjs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading final csv file\n",
    "def load_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.drop(['filename'],axis=1, inplace=True)\n",
    "    classes = df.pop('class_name').unique()\n",
    "    y = df.pop('class_no')\n",
    "    \n",
    "    X = df.astype('float64')\n",
    "    y = keras.utils.to_categorical(y)\n",
    "    \n",
    "    return X, y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23296ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cf7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "\n",
    "    It is the maximum of two values:\n",
    "    * Torso size multiplied by `torso_size_multiplier`\n",
    "    * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                      BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                     BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "    return pose_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91e11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "    scaling it to a constant pose size.\n",
    "  \"\"\"\n",
    "  # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f422449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4759a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train):\n",
    "    processed_X_train = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        embedding = landmarks_to_embedding(tf.reshape(tf.convert_to_tensor(X_train.iloc[i]), (1, 51)))\n",
    "        processed_X_train.append(tf.reshape(embedding, (34)))\n",
    "    return tf.convert_to_tensor(processed_X_train)\n",
    "\n",
    "\n",
    "X, y, class_names = load_csv('train_data.csv')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n",
    "X_test, y_test, _ = load_csv('test_data.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0557cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X_train = preprocess_data(X_train)\n",
    "processed_X_val =  preprocess_data(X_val)\n",
    "processed_X_test = preprocess_data(X_test)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(34))\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(inputs)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b08ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e41ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "checkpoint_path = \"weights.best.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                              patience=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b7328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.autograph.experimental.set_loop_options(\n",
    "    shape_invariants=[(outputs, tf.TensorShape([None, 2]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf3d618f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------TRAINING----------------\n",
      "Epoch 1/200\n",
      "138/150 [==========================>...] - ETA: 0s - loss: 0.7293 - accuracy: 0.6467\n",
      "Epoch 1: val_accuracy improved from -inf to 0.68957, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.7195 - accuracy: 0.6494 - val_loss: 0.5431 - val_accuracy: 0.6896\n",
      "Epoch 2/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.7172\n",
      "Epoch 2: val_accuracy improved from 0.68957 to 0.81754, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7172 - val_loss: 0.4228 - val_accuracy: 0.8175\n",
      "Epoch 3/200\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.4370 - accuracy: 0.8051\n",
      "Epoch 3: val_accuracy improved from 0.81754 to 0.88863, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8044 - val_loss: 0.3387 - val_accuracy: 0.8886\n",
      "Epoch 4/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.8479\n",
      "Epoch 4: val_accuracy improved from 0.88863 to 0.92654, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8479 - val_loss: 0.2753 - val_accuracy: 0.9265\n",
      "Epoch 5/200\n",
      "129/150 [========================>.....] - ETA: 0s - loss: 0.3165 - accuracy: 0.8808\n",
      "Epoch 5: val_accuracy did not improve from 0.92654\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8768 - val_loss: 0.2400 - val_accuracy: 0.9100\n",
      "Epoch 6/200\n",
      "134/150 [=========================>....] - ETA: 0s - loss: 0.2946 - accuracy: 0.9007\n",
      "Epoch 6: val_accuracy improved from 0.92654 to 0.94313, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.9045 - val_loss: 0.2081 - val_accuracy: 0.9431\n",
      "Epoch 7/200\n",
      "133/150 [=========================>....] - ETA: 0s - loss: 0.2663 - accuracy: 0.9102\n",
      "Epoch 7: val_accuracy improved from 0.94313 to 0.95024, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.9087 - val_loss: 0.1799 - val_accuracy: 0.9502\n",
      "Epoch 8/200\n",
      "134/150 [=========================>....] - ETA: 0s - loss: 0.2419 - accuracy: 0.9207\n",
      "Epoch 8: val_accuracy did not improve from 0.95024\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9225 - val_loss: 0.1901 - val_accuracy: 0.9408\n",
      "Epoch 9/200\n",
      "135/150 [==========================>...] - ETA: 0s - loss: 0.2241 - accuracy: 0.9315\n",
      "Epoch 9: val_accuracy did not improve from 0.95024\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9321 - val_loss: 0.1719 - val_accuracy: 0.9479\n",
      "Epoch 10/200\n",
      "143/150 [===========================>..] - ETA: 0s - loss: 0.2187 - accuracy: 0.9309\n",
      "Epoch 10: val_accuracy improved from 0.95024 to 0.95972, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9317 - val_loss: 0.1557 - val_accuracy: 0.9597\n",
      "Epoch 11/200\n",
      "123/150 [=======================>......] - ETA: 0s - loss: 0.1975 - accuracy: 0.9329\n",
      "Epoch 11: val_accuracy improved from 0.95972 to 0.96682, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9351 - val_loss: 0.1360 - val_accuracy: 0.9668\n",
      "Epoch 12/200\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.1821 - accuracy: 0.9457\n",
      "Epoch 12: val_accuracy did not improve from 0.96682\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1844 - accuracy: 0.9447 - val_loss: 0.1442 - val_accuracy: 0.9597\n",
      "Epoch 13/200\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.1823 - accuracy: 0.9443\n",
      "Epoch 13: val_accuracy did not improve from 0.96682\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9443 - val_loss: 0.1259 - val_accuracy: 0.9668\n",
      "Epoch 14/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.1635 - accuracy: 0.9502\n",
      "Epoch 14: val_accuracy did not improve from 0.96682\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9501 - val_loss: 0.1255 - val_accuracy: 0.9668\n",
      "Epoch 15/200\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.1659 - accuracy: 0.9490\n",
      "Epoch 15: val_accuracy improved from 0.96682 to 0.96919, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9493 - val_loss: 0.1152 - val_accuracy: 0.9692\n",
      "Epoch 16/200\n",
      "126/150 [========================>.....] - ETA: 0s - loss: 0.1633 - accuracy: 0.9554\n",
      "Epoch 16: val_accuracy did not improve from 0.96919\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9552 - val_loss: 0.1100 - val_accuracy: 0.9692\n",
      "Epoch 17/200\n",
      "137/150 [==========================>...] - ETA: 0s - loss: 0.1479 - accuracy: 0.9557\n",
      "Epoch 17: val_accuracy did not improve from 0.96919\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9552 - val_loss: 0.1235 - val_accuracy: 0.9668\n",
      "Epoch 18/200\n",
      "125/150 [========================>.....] - ETA: 0s - loss: 0.1357 - accuracy: 0.9575\n",
      "Epoch 18: val_accuracy improved from 0.96919 to 0.97156, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9552 - val_loss: 0.1056 - val_accuracy: 0.9716\n",
      "Epoch 19/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9595\n",
      "Epoch 19: val_accuracy did not improve from 0.97156\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9606 - val_loss: 0.0996 - val_accuracy: 0.9716\n",
      "Epoch 20/200\n",
      "132/150 [=========================>....] - ETA: 0s - loss: 0.1410 - accuracy: 0.9579\n",
      "Epoch 20: val_accuracy improved from 0.97156 to 0.97630, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9577 - val_loss: 0.1092 - val_accuracy: 0.9763\n",
      "Epoch 21/200\n",
      "138/150 [==========================>...] - ETA: 0s - loss: 0.1366 - accuracy: 0.9633\n",
      "Epoch 21: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9627 - val_loss: 0.0972 - val_accuracy: 0.9716\n",
      "Epoch 22/200\n",
      "140/150 [===========================>..] - ETA: 0s - loss: 0.1391 - accuracy: 0.9567\n",
      "Epoch 22: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9560 - val_loss: 0.0934 - val_accuracy: 0.9763\n",
      "Epoch 23/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 0.9628\n",
      "Epoch 23: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9631 - val_loss: 0.0881 - val_accuracy: 0.9739\n",
      "Epoch 24/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9639\n",
      "Epoch 24: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9640 - val_loss: 0.0874 - val_accuracy: 0.9739\n",
      "Epoch 25/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9648\n",
      "Epoch 25: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9648 - val_loss: 0.0838 - val_accuracy: 0.9763\n",
      "Epoch 26/200\n",
      "134/150 [=========================>....] - ETA: 0s - loss: 0.1096 - accuracy: 0.9697\n",
      "Epoch 26: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9682 - val_loss: 0.0872 - val_accuracy: 0.9763\n",
      "Epoch 27/200\n",
      "142/150 [===========================>..] - ETA: 0s - loss: 0.1027 - accuracy: 0.9692\n",
      "Epoch 27: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9686 - val_loss: 0.0850 - val_accuracy: 0.9739\n",
      "Epoch 28/200\n",
      "141/150 [===========================>..] - ETA: 0s - loss: 0.1069 - accuracy: 0.9645\n",
      "Epoch 28: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9656 - val_loss: 0.0913 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "126/150 [========================>.....] - ETA: 0s - loss: 0.1079 - accuracy: 0.9688\n",
      "Epoch 29: val_accuracy did not improve from 0.97630\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9698 - val_loss: 0.0859 - val_accuracy: 0.9739\n",
      "Epoch 30/200\n",
      "139/150 [==========================>...] - ETA: 0s - loss: 0.1026 - accuracy: 0.9694\n",
      "Epoch 30: val_accuracy improved from 0.97630 to 0.97867, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9698 - val_loss: 0.0801 - val_accuracy: 0.9787\n",
      "Epoch 31/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9703\n",
      "Epoch 31: val_accuracy did not improve from 0.97867\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9690 - val_loss: 0.0798 - val_accuracy: 0.9763\n",
      "Epoch 32/200\n",
      "135/150 [==========================>...] - ETA: 0s - loss: 0.0989 - accuracy: 0.9699\n",
      "Epoch 32: val_accuracy did not improve from 0.97867\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9690 - val_loss: 0.0759 - val_accuracy: 0.9716\n",
      "Epoch 33/200\n",
      "126/150 [========================>.....] - ETA: 0s - loss: 0.0847 - accuracy: 0.9762\n",
      "Epoch 33: val_accuracy improved from 0.97867 to 0.98341, saving model to weights.best.hdf5\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9749 - val_loss: 0.0713 - val_accuracy: 0.9834\n",
      "Epoch 34/200\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9709\n",
      "Epoch 34: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9707 - val_loss: 0.0714 - val_accuracy: 0.9810\n",
      "Epoch 35/200\n",
      "130/150 [=========================>....] - ETA: 0s - loss: 0.0896 - accuracy: 0.9784\n",
      "Epoch 35: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9782 - val_loss: 0.0810 - val_accuracy: 0.9739\n",
      "Epoch 36/200\n",
      "135/150 [==========================>...] - ETA: 0s - loss: 0.0922 - accuracy: 0.9731\n",
      "Epoch 36: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9711 - val_loss: 0.0644 - val_accuracy: 0.9810\n",
      "Epoch 37/200\n",
      "138/150 [==========================>...] - ETA: 0s - loss: 0.0911 - accuracy: 0.9683\n",
      "Epoch 37: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9694 - val_loss: 0.0689 - val_accuracy: 0.9810\n",
      "Epoch 38/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.9797\n",
      "Epoch 38: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9799 - val_loss: 0.0718 - val_accuracy: 0.9834\n",
      "Epoch 39/200\n",
      "128/150 [========================>.....] - ETA: 0s - loss: 0.0772 - accuracy: 0.9800\n",
      "Epoch 39: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9778 - val_loss: 0.0706 - val_accuracy: 0.9787\n",
      "Epoch 40/200\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.0788 - accuracy: 0.9753\n",
      "Epoch 40: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9753 - val_loss: 0.0654 - val_accuracy: 0.9763\n",
      "Epoch 41/200\n",
      "131/150 [=========================>....] - ETA: 0s - loss: 0.0812 - accuracy: 0.9785\n",
      "Epoch 41: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9791 - val_loss: 0.0636 - val_accuracy: 0.9787\n",
      "Epoch 42/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9786\n",
      "Epoch 42: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9786 - val_loss: 0.0710 - val_accuracy: 0.9739\n",
      "Epoch 43/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 0.9726\n",
      "Epoch 43: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9724 - val_loss: 0.0707 - val_accuracy: 0.9787\n",
      "Epoch 44/200\n",
      "127/150 [========================>.....] - ETA: 0s - loss: 0.0702 - accuracy: 0.9759\n",
      "Epoch 44: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9765 - val_loss: 0.0687 - val_accuracy: 0.9810\n",
      "Epoch 45/200\n",
      "138/150 [==========================>...] - ETA: 0s - loss: 0.0765 - accuracy: 0.9724\n",
      "Epoch 45: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9703 - val_loss: 0.0712 - val_accuracy: 0.9810\n",
      "Epoch 46/200\n",
      "137/150 [==========================>...] - ETA: 0s - loss: 0.0728 - accuracy: 0.9754\n",
      "Epoch 46: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9757 - val_loss: 0.0558 - val_accuracy: 0.9810\n",
      "Epoch 47/200\n",
      "133/150 [=========================>....] - ETA: 0s - loss: 0.0760 - accuracy: 0.9746\n",
      "Epoch 47: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9744 - val_loss: 0.0728 - val_accuracy: 0.9810\n",
      "Epoch 48/200\n",
      "138/150 [==========================>...] - ETA: 0s - loss: 0.0761 - accuracy: 0.9760\n",
      "Epoch 48: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9770 - val_loss: 0.0607 - val_accuracy: 0.9810\n",
      "Epoch 49/200\n",
      "133/150 [=========================>....] - ETA: 0s - loss: 0.0690 - accuracy: 0.9765\n",
      "Epoch 49: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9770 - val_loss: 0.0512 - val_accuracy: 0.9810\n",
      "Epoch 50/200\n",
      "141/150 [===========================>..] - ETA: 0s - loss: 0.0830 - accuracy: 0.9747\n",
      "Epoch 50: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9740 - val_loss: 0.0602 - val_accuracy: 0.9834\n",
      "Epoch 51/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9793\n",
      "Epoch 51: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9791 - val_loss: 0.0581 - val_accuracy: 0.9810\n",
      "Epoch 52/200\n",
      "142/150 [===========================>..] - ETA: 0s - loss: 0.0796 - accuracy: 0.9732\n",
      "Epoch 52: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9736 - val_loss: 0.0593 - val_accuracy: 0.9810\n",
      "Epoch 53/200\n",
      "126/150 [========================>.....] - ETA: 0s - loss: 0.0597 - accuracy: 0.9797\n",
      "Epoch 53: val_accuracy did not improve from 0.98341\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9778 - val_loss: 0.0551 - val_accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print('--------------TRAINING----------------')\n",
    "history = model.fit(processed_X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(processed_X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5583a22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------EVAUATION----------------\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7500 - accuracy: 0.8155\n",
      "LOSS:  0.7499910593032837\n",
      "ACCURACY:  0.815460205078125\n"
     ]
    }
   ],
   "source": [
    "print('-----------------EVAUATION----------------')\n",
    "loss, accuracy = model.evaluate(processed_X_test, y_test)\n",
    "print('LOSS: ', loss)\n",
    "print(\"ACCURACY: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908dee67",
   "metadata": {},
   "source": [
    "# Save the CNN as pickle for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9413730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d01ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curls' 'legs' 'no_pose']\n"
     ]
    }
   ],
   "source": [
    "X, y, class_names = load_csv('train_data.csv')\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bff68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14198e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
