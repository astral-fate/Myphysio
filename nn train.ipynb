{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43235291",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data import BodyPart \n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading final csv file\n",
    "def load_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.drop(['filename'],axis=1, inplace=True)\n",
    "    classes = df.pop('class_name').unique()\n",
    "    y = df.pop('class_no')\n",
    "    \n",
    "    X = df.astype('float64')\n",
    "    y = keras.utils.to_categorical(y)\n",
    "    \n",
    "    return X, y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23296ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cf7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "\n",
    "    It is the maximum of two values:\n",
    "    * Torso size multiplied by `torso_size_multiplier`\n",
    "    * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                      BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                     BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "    return pose_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91e11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "    scaling it to a constant pose size.\n",
    "  \"\"\"\n",
    "  # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f422449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4759a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train):\n",
    "    processed_X_train = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        embedding = landmarks_to_embedding(tf.reshape(tf.convert_to_tensor(X_train.iloc[i]), (1, 51)))\n",
    "        processed_X_train.append(tf.reshape(embedding, (34)))\n",
    "    return tf.convert_to_tensor(processed_X_train)\n",
    "\n",
    "\n",
    "X, y, class_names = load_csv('train_data.csv')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n",
    "X_test, y_test, _ = load_csv('test_data.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0557cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X_train = preprocess_data(X_train)\n",
    "processed_X_val =  preprocess_data(X_val)\n",
    "processed_X_test = preprocess_data(X_test)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(34))\n",
    "layer = keras.layers.Dense(256, activation=tf.nn.relu6)(inputs)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d01ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['curls' 'legs' 'no_pose']\n"
     ]
    }
   ],
   "source": [
    "X, y, class_names = load_csv('train_data.csv')\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b08ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e41ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a checkpoint callback to store the checkpoint that has the highest\n",
    "# validation accuracy.\n",
    "checkpoint_path = \"weights.best.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
    "                                              patience=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b7328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.autograph.experimental.set_loop_options(\n",
    "    shape_invariants=[(outputs, tf.TensorShape([None, 2]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf3d618f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------TRAINING----------------\n",
      "Epoch 1/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9858\n",
      "Epoch 1: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.0546 - val_accuracy: 0.9905\n",
      "Epoch 2/200\n",
      "142/150 [===========================>..] - ETA: 0s - loss: 0.0424 - accuracy: 0.9872\n",
      "Epoch 2: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0720 - val_accuracy: 0.9834\n",
      "Epoch 3/200\n",
      "146/150 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9842\n",
      "Epoch 3: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 0.0584 - val_accuracy: 0.9858\n",
      "Epoch 4/200\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9813\n",
      "Epoch 4: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9816 - val_loss: 0.0946 - val_accuracy: 0.9787\n",
      "Epoch 5/200\n",
      "139/150 [==========================>...] - ETA: 0s - loss: 0.0418 - accuracy: 0.9879\n",
      "Epoch 5: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9870 - val_loss: 0.0510 - val_accuracy: 0.9905\n",
      "Epoch 6/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9844\n",
      "Epoch 6: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9841 - val_loss: 0.0581 - val_accuracy: 0.9905\n",
      "Epoch 7/200\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.0447 - accuracy: 0.9861\n",
      "Epoch 7: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0621 - val_accuracy: 0.9858\n",
      "Epoch 8/200\n",
      "138/150 [==========================>...] - ETA: 0s - loss: 0.0393 - accuracy: 0.9864\n",
      "Epoch 8: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.0523 - val_accuracy: 0.9882\n",
      "Epoch 9/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9879\n",
      "Epoch 9: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9879 - val_loss: 0.0519 - val_accuracy: 0.9882\n",
      "Epoch 10/200\n",
      "132/150 [=========================>....] - ETA: 0s - loss: 0.0467 - accuracy: 0.9882\n",
      "Epoch 10: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9870 - val_loss: 0.0609 - val_accuracy: 0.9858\n",
      "Epoch 11/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9882\n",
      "Epoch 11: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9883 - val_loss: 0.0549 - val_accuracy: 0.9882\n",
      "Epoch 12/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9823\n",
      "Epoch 12: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.0907 - val_accuracy: 0.9810\n",
      "Epoch 13/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9849\n",
      "Epoch 13: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9841 - val_loss: 0.0617 - val_accuracy: 0.9929\n",
      "Epoch 14/200\n",
      "132/150 [=========================>....] - ETA: 0s - loss: 0.0473 - accuracy: 0.9830\n",
      "Epoch 14: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.0764 - val_accuracy: 0.9882\n",
      "Epoch 15/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9767\n",
      "Epoch 15: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9770 - val_loss: 0.0609 - val_accuracy: 0.9882\n",
      "Epoch 16/200\n",
      "136/150 [==========================>...] - ETA: 0s - loss: 0.0613 - accuracy: 0.9779\n",
      "Epoch 16: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.0803 - val_accuracy: 0.9858\n",
      "Epoch 17/200\n",
      "134/150 [=========================>....] - ETA: 0s - loss: 0.0482 - accuracy: 0.9860\n",
      "Epoch 17: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.0694 - val_accuracy: 0.9882\n",
      "Epoch 18/200\n",
      "139/150 [==========================>...] - ETA: 0s - loss: 0.0508 - accuracy: 0.9852\n",
      "Epoch 18: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9853 - val_loss: 0.0526 - val_accuracy: 0.9905\n",
      "Epoch 19/200\n",
      "137/150 [==========================>...] - ETA: 0s - loss: 0.0408 - accuracy: 0.9859\n",
      "Epoch 19: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.0750 - val_accuracy: 0.9858\n",
      "Epoch 20/200\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9887\n",
      "Epoch 20: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9887 - val_loss: 0.0637 - val_accuracy: 0.9858\n",
      "Epoch 21/200\n",
      "147/150 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9915\n",
      "Epoch 21: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.0557 - val_accuracy: 0.9905\n",
      "Epoch 22/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9861\n",
      "Epoch 22: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9858 - val_loss: 0.0559 - val_accuracy: 0.9858\n",
      "Epoch 23/200\n",
      "148/150 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9890\n",
      "Epoch 23: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0642 - val_accuracy: 0.9858\n",
      "Epoch 24/200\n",
      "136/150 [==========================>...] - ETA: 0s - loss: 0.0565 - accuracy: 0.9830\n",
      "Epoch 24: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9837 - val_loss: 0.0693 - val_accuracy: 0.9810\n",
      "Epoch 25/200\n",
      "127/150 [========================>.....] - ETA: 0s - loss: 0.0463 - accuracy: 0.9852\n",
      "Epoch 25: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9853 - val_loss: 0.0604 - val_accuracy: 0.9858\n",
      "Epoch 26/200\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.0272 - accuracy: 0.9918\n",
      "Epoch 26: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0668 - val_accuracy: 0.9858\n",
      "Epoch 27/200\n",
      "145/150 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9836\n",
      "Epoch 27: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9837 - val_loss: 0.0554 - val_accuracy: 0.9858\n",
      "Epoch 28/200\n",
      "126/150 [========================>.....] - ETA: 0s - loss: 0.0253 - accuracy: 0.9931\n",
      "Epoch 28: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0936 - val_accuracy: 0.9834\n",
      "Epoch 29/200\n",
      "141/150 [===========================>..] - ETA: 0s - loss: 0.0577 - accuracy: 0.9814\n",
      "Epoch 29: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9824 - val_loss: 0.0670 - val_accuracy: 0.9834\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/150 [========================>.....] - ETA: 0s - loss: 0.0470 - accuracy: 0.9826\n",
      "Epoch 30: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9837 - val_loss: 0.0684 - val_accuracy: 0.9834\n",
      "Epoch 31/200\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9904\n",
      "Epoch 31: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 0.0674 - val_accuracy: 0.9905\n",
      "Epoch 32/200\n",
      "144/150 [===========================>..] - ETA: 0s - loss: 0.0467 - accuracy: 0.9848\n",
      "Epoch 32: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9841 - val_loss: 0.0725 - val_accuracy: 0.9858\n",
      "Epoch 33/200\n",
      "139/150 [==========================>...] - ETA: 0s - loss: 0.0314 - accuracy: 0.9892\n",
      "Epoch 33: val_accuracy did not improve from 0.99289\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.0938 - val_accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print('--------------TRAINING----------------')\n",
    "history = model.fit(processed_X_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=200,\n",
    "                    validation_data=(processed_X_val, y_val),\n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5583a22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------EVAUATION----------------\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.8134 - accuracy: 0.8601\n",
      "LOSS:  0.8133879899978638\n",
      "ACCURACY:  0.8600806593894958\n"
     ]
    }
   ],
   "source": [
    "print('-----------------EVAUATION----------------')\n",
    "loss, accuracy = model.evaluate(processed_X_test, y_test)\n",
    "print('LOSS: ', loss)\n",
    "print(\"ACCURACY: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908dee67",
   "metadata": {},
   "source": [
    "# Save the CNN as pickle for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9413730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained_model24.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bff68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14198e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
